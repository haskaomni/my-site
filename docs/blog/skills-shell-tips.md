---
title: Shell + Skills + 压缩：让长时间运行的 Agent 做真正工作的技巧
description: OpenAI 官方博客翻译 — 关于 Skills、Shell 工具和服务端压缩的实践指南
---

# Shell + Skills + 压缩：让长时间运行的 Agent 做真正工作的技巧

**来源：[OpenAI 开发者博客](https://developers.openai.com/blog/skills-shell-tips)**

---

我们正在从单轮助手转向能处理真实知识工作的长时间运行 Agent：阅读大型数据集、更新文件、编写应用。

基于开发者反馈和我们自己构建 Codex 及内部 Agent 的经验，我们发布了一组新的 Agent 原语，让长周期工作更加实用：

- **Skills**（与 Agent Skills 开放标准对齐）：可复用、有版本控制的指令，你可以挂载到容器中，让 Agent 更可靠地执行任务。

- **升级版 Shell 工具**：一个 OpenAI 托管的容器，具有受控的互联网访问，Agent 可以在其中安装依赖、运行脚本、写入输出（例如报告和产物）。

- **服务端压缩（Compaction）**：一种简单的方式来自动压缩长时间 Agent 运行的上下文，让你永远不会触及上下文窗口限制。

文档和 API 参考分别涵盖了上述每个项目。这篇文章聚焦于我们迄今为止观察到效果最好的非显而易见的技巧和模式，既来自我们在 OpenAI 的工作，也来自早期 Skills 客户 Glean 的生产实践。

## 简要心智模型

### Skills："程序"——模型可以按需加载

一个 Skill 是一组文件加上一个 SKILL.md 清单，包含前置元数据和指令。可以把它想象成：一个有版本的操作手册，模型在需要做真正工作时可以查阅。

当 Skills 可用时，平台会向模型暴露每个 Skill 的名称、描述和路径。模型使用这些元数据来决定是否调用某个 Skill。如果调用，它会读取 SKILL.md 获取完整工作流程。

### Shell 工具："执行层"——给 Agent 的

Shell 工具让模型在真实的终端环境中工作，有两种方式：

- OpenAI 管理的托管容器。
- 你自己执行的本地 Shell 运行时（相同的工具语义，但你控制机器）。

托管 Shell 通过 Responses API 运行，这意味着你的请求附带有状态的工作、工具调用、多轮续接和产物。

### 压缩：让长时间运行持续进行

随着工作流变长，它们会遇到上下文窗口限制。服务端压缩通过管理上下文窗口和自动压缩对话历史来保持长时间运行的持续性。

Responses API 中的压缩给你两种处理方式：

- **服务端压缩（新）**：当上下文超过阈值时，压缩在流中自动运行，无需单独的压缩调用。
- **独立 compact 端点**：当你想显式控制压缩时机时，使用 `/responses/compact`。

### 为什么它们搭配起来更好

- **Skills** 通过将稳定的程序和示例移入可复用包，减少提示词意大利面。
- **Shell** 提供完整的执行环境，让你安装代码、运行脚本、写入输出。
- **压缩** 在长时间运行中保持连续性，让同一工作流可以持续执行，无需手动上下文手术。
- **三者结合**，你获得了有真实执行能力的可重复工作流，而不需要把系统提示词变成一个脆弱的巨型文档。

## 技巧与窍门

### 1) 像路由逻辑一样写 Skill 描述（不是营销文案）

你的 Skill 描述实际上是模型的决策边界。它应该回答：

- 什么时候应该用这个？
- 什么时候不应该用这个？
- 输出和成功标准是什么？

一个实用的模式是在描述中直接包含一个简短的"何时使用 vs. 何时不使用"块，并保持具体（输入、涉及的工具、预期产物）。

### 2) 添加反面示例和边缘情况以减少误触发

一个令人惊讶的失败模式是：提供 Skills 最初可能*降低*正确触发率。我们看到有效的修复方法是反面示例加边缘情况覆盖。

实践中，这意味着写几个明确的"当……时不要调用此 Skill"的案例（以及该做什么替代）。这帮助模型更干净地路由，特别是当你有多个乍一看相似的 Skills 时。

Glean 直接经历了这一点：基于 Skill 的路由最初在定向评估中触发率下降了约 20%，然后在描述中添加反面示例和边缘情况覆盖后恢复。

### 3) 把模板和示例放在 Skill 内部（未使用时基本免费）

如果你一直在把模板塞进系统提示词里，停下来。

Skill 内部的模板和示例有两个优势：

- 它们在需要时准确可用（当 Skill 被调用时）。
- 它们不会为无关查询膨胀 token。

这对知识工作输出特别有效，比如：

- 结构化报告
- 升级分诊摘要
- 客户计划
- 数据分析文档

Glean 报告说，这个模式带来了他们生产环境中最大的质量和延迟提升，因为那些示例只在 Skill 触发时加载。

### 4) 尽早为长时间运行设计——使用容器复用和压缩

长周期 Agent 很少能通过一次性提示成功。从一开始就为连续性做规划：

- 跨步骤复用同一个容器——当你想要稳定的依赖、缓存文件和中间输出时。
- 传递 `previous_response_id`，这样模型可以在同一线程中继续工作。
- 把压缩作为默认的长时间运行原语，而不是紧急回退方案。

这种组合减少了重启行为，保持多步骤任务在线程增长时的一致性。

### 5) 需要确定性时，明确告诉模型使用该 Skill

默认行为是模型自行决定何时使用 Skill。这通常是你想要的。

但当你运行一个有明确契约的生产工作流时（你宁愿确定性而非聪明），直接说：

"使用 \<skill name\> skill。"

这是你能拉动的最简单的可靠性杠杆。它把模糊路由变成了明确契约。

### 6) 将 Skills + 网络视为高风险组合（为隔离而设计）

这是现在容易忽略、以后难以修复的安全提示。

将 Skills 与开放网络访问组合会创造数据泄露的高风险路径。如果使用网络，保持网络白名单严格，假设工具输出不可信，避免在用户期望强确认控制的面向消费者的流程中同时使用开放互联网和强大程序。

一个强有力的默认姿态：

- Skills：允许
- Shell：允许
- 网络：仅在最小白名单下按请求启用，用于范围狭窄的任务

### 7) 让 /mnt/data 成为产物的交接边界

对于托管 Shell 工作流，把 `/mnt/data` 当作写入输出的标准位置——你将从那里检索、审查或传递到后续步骤。例如报告、清洗后的数据集和完成的电子表格。

一个好的心智模型：工具写入磁盘，模型对磁盘进行推理，开发者从磁盘检索。

### 8) 理解白名单是一个两层系统（组织级和请求级）

网络在两个地方控制：

- **组织级白名单**（由管理员配置），设置允许的最大目标范围。
- **请求级 network_policy**，必须是组织白名单的子集。

两个在运维上重要的含义：

- 保持组织白名单小而稳定（"你信任的已批准目标"集合）。
- 保持请求白名单更小（"这一个任务需要的目标"集合）。

如果请求包含组织白名单之外的域名，将会报错。

### 9) 使用 domain_secrets 进行认证调用（避免凭证泄露）

如果白名单域名需要认证头，使用 `domain_secrets`，这样模型永远看不到原始凭证。

运行时，模型看到的是占位符（例如 `$API_KEY`），边车（sidecar）只为已批准的目标注入真实值。这是你的 Agent 需要从容器内调用受保护 API 时的强有力默认做法。

### 10) 在云端和本地使用相同的 API

你可以在不承诺托管一切的情况下使用这两个原语：

- Skills 在托管 Shell 和本地 Shell 模式下都可工作。
- Shell 有本地执行模式，你自己执行 `shell_call` 并将 `shell_call_output` 返回给模型。
- 如果你使用 Agents SDK，也可以插入自己的 Shell 执行器。

一个实用的开发循环：

- **从本地开始**（快速迭代、访问内部工具、方便调试）。
- **迁移到托管容器**——当你想要可重复性、隔离性和部署一致性时。
- **跨两种模式保持 Skills 不变**（工作流保持稳定，即使执行位置变了）。

## 三种构建模式

虽然你应该随意试验这些新的 Agent 原语，这里有三个如何组合它们构建实用应用的示例。

### 模式 A：安装 → 获取 → 写入产物

这是受益于托管 Shell 最简单的方式：Agent 安装依赖、获取外部数据、生产一个具体交付物。

例如：

- 安装几个库
- 抓取数据或调用 API
- 将报告写入 `/mnt/data/report.md`

这个模式是"做真实工作的 Agent"的基础，因为它创建了一个清晰的审查边界：你的应用可以向用户展示产物、记录它、对比差异、或将它输入到后续步骤。

### 模式 B：Skills + Shell 实现可重复工作流

一旦你构建了一两个成功的 Shell 工作流，你会注意到下一个问题：这能工作，但当提示词漂移时可靠性会下降。

这就是 Skills 登场的地方。以下是一个持久的结构：

- 将工作流（步骤、护栏、模板）编码在一个 Skill 中。
- 将 Skill 挂载到你的 Shell 环境中。
- 让 Agent 按照 Skill 确定性地生产产物。

这对以下工作流特别有效：

- 电子表格分析或编辑
- 数据集清洗 + 摘要生成
- 重复业务流程的标准化报告生成

### 模式 C（高级）：Skills 作为企业工作流载体

我们看到的一个早期模式是：从单工具调用到多工具编排之间存在准确性损失。Skills 可以通过让工具推理更程序化来弥合这个差距，而不会膨胀系统提示词。

来自 Glean 的一个具体示例：

- 一个面向 Salesforce 的 Skill 将评估准确率从 73% 提升到 85%，并将首 token 时间减少了 18.1%。
- 实用策略包括仔细路由、反面示例、以及在 Skill 内部嵌入模板/示例。
- Glean 还使用 Skills 来编码企业工作流中的重复任务，包括客户规划、升级分诊和品牌一致的内容生成。

这就是事情变得强大的形态。Skills 成为活的 SOP（标准操作程序）：随着你的组织演进而更新，由 Agent 一致地执行。

## 一次构建，到处运行

当长时间运行的 Agent 既能遵循程序又能在计算机上做真实工作时，它们会变得极其有用。Skills、托管 Shell 和压缩创建了这个基础。总结：

- 使用 **Skills** 编码"如何做"（程序、模板、护栏）。
- 使用 **Shell** 执行"做什么"（安装、运行、写入产物）。
- 使用**压缩**保持长时间运行的一致性（无需手动管理上下文）。
- 快速迭代时**从本地开始**。
- 需要可重复、隔离的执行时**迁移到托管容器**。
- 通过组织级和请求级白名单**锁定网络**，认证调用使用 domain secrets。

开始在你自己的应用中构建吧。查看 [Skills 文档](https://platform.openai.com/docs/guides/tools-skills)、[Shell 文档](https://platform.openai.com/docs/guides/tools-shell) 和[压缩文档](https://platform.openai.com/docs/guides/context-management)了解更多。
